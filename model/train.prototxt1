name: "GAN"
layer {
    name: 'input_data'
    type: 'Python'
    top: 'gray_image'
    top: 'color_image'
    top: 'label'
    python_param {
        module: 'data_layer'
        layer: 'DataLayer'
        #param_str: " 'batch_size': 32 " #and roor_folder folder and train.txt source height weight
        param_str: "{\'batch_size\': 16 , \'root_folder\': \'out_unaug_64x64/\', \'source\': \'train.txt\'}"
    }
}

layer {
    name: "g_conv_1"
    type: "Convolution"
    bottom: "gray_image"
    top: "g_conv_1"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 16
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_1"
	top: "g_conv_1"
	name: "g_bn_1"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_1"
	top: "g_conv_1"
	name: "g_scale_1"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_1"
    type: "ReLU"
    bottom: "g_conv_1"
    top: "g_conv_1"
}

layer {
    name: "g_conv_2"
    type: "Convolution"
    bottom: "g_conv_1"
    top: "g_conv_2"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 32
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_2"
	top: "g_conv_2"
	name: "g_bn_2"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_2"
	top: "g_conv_2"
	name: "g_scale_2"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_2"
    type: "ReLU"
    bottom: "g_conv_2"
    top: "g_conv_2"
}

layer {
    name: "g_pooling_2"
    type: "Pooling"
    bottom: "g_conv_2"
    top: "g_pooling_2"
    top: "g_pooling_2_mask"
    pooling_param{
        pool: MAX
        kernel_size: 2
        stride: 2
    }
}
layer {
    name: "g_conv_3"
    type: "Convolution"
    bottom: "g_pooling_2"
    top: "g_conv_3"
    param {
        lr_mult: -1
        decay_mult: -1

    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 64
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_3"
	top: "g_conv_3"
	name: "g_bn_"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_3"
	top: "g_conv_3"
	name: "g_scale_3"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_3"
    type: "ReLU"
    bottom: "g_conv_3"
    top: "g_conv_3"
}

layer {
    name: "g_pooling_3"
    type: "Pooling"
    bottom: "g_conv_3"
    top: "g_pooling_3"
    top: "g_pooling_3_mask"
    pooling_param{
        pool: MAX
        kernel_size:2
        stride: 2
    }
}

layer {
    name: "g_conv_4"
    type: "Convolution"
    bottom: "g_pooling_3"
    top: "g_conv_4"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 128
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_4"
	top: "g_conv_4"
	name: "g_bn_4"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_4"
	top: "g_conv_4"
	name: "g_scale_4"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_4"
    type: "ReLU"
    bottom: "g_conv_4"
    top: "g_conv_4"
}

layer {
    name: "g_conv_5"
    type: "Convolution"
    bottom: "g_conv_4"
    top: "g_conv_5"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 64
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_5"
	top: "g_conv_5"
	name: "g_bn_5"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_5"
	top: "g_conv_5"
	name: "g_scale_5"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_5"
    type: "ReLU"
    bottom: "g_conv_5"
    top: "g_conv_5"
}
#upsample

layer {
  name: "g_upsample_1"
  type: "Upsample"
  bottom: "g_conv_5"
  bottom: "g_pooling_3_mask"
  top: "g_upsample_1"
  upsample_param {
    scale: 2
    #upsample_w: 30
    #upsample_h: 23
  }
}

#layer {
  #name: "g_deconv_1"
  #type: "Deconvolution"
  #bottom: "g_relu_5"
  #top: "g_deconv_1"
  #param {
    #lr_mult: 0
  #}
  #convolution_param {
    #num_output: 256
    #bias_term: false
    #kernel_size: 3
    #stride: 1
    #pad:1
  #}
#}

layer {
    name: "g_conv_6"
    type: "Convolution"
    bottom: "g_upsample_1"
    top: "g_conv_6"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 32
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_6"
	top: "g_conv_6"
	name: "g_bn_6"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_6"
	top: "g_conv_6"
	name: "g_scale_6"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_6"
    type: "ReLU"
    bottom: "g_conv_6"
    top: "g_conv_6"
}
#upsampling
layer {
  name: "g_upsample_2"
  type: "Upsample"
  bottom: "g_conv_6"
  bottom: "g_pooling_2_mask"
  top: "g_upsample_2"
  upsample_param {
    scale: 2
    #upsample_w: 30
    #upsample_h: 23
  }
}

#layer {
  #name: "g_deconv_2"
  #type: "Deconvolution"
  #bottom: "g_relu_6"
  #top: "g_deconv_2"
  #param {
    #lr_mult: 0
  #}
  #convolution_param {
    #num_output: 128
    #bias_term: false
    #kernel_size: 3
    #stride: 1
    #pad:1
  #}
#}

layer {
    name: "g_conv_7"
    type: "Convolution"
    bottom: "g_upsample_2"
    top: "g_conv_7"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 64
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_7"
	top: "g_conv_7"
	name: "g_bn_7"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_7"
	top: "g_conv_7"
	name: "g_scale_7"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_7"
    type: "ReLU"
    bottom: "g_conv_7"
    top: "g_conv_7"
}

layer {
    name: "concat"
    type: "Concat"
    bottom: "gray_image"
    bottom: "g_conv_7"
    top: "concat"
    concat_param{
        axis : 1
    }
}

layer {
    name: "g_conv_8"
    type: "Convolution"
    bottom: "concat"
    top: "g_conv_8"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 32
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_8"
	top: "g_conv_8"
	name: "g_bn_8"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_8"
	top: "g_conv_8"
	name: "g_scale_8"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_relu_8"
    type: "ReLU"
    bottom: "g_conv_8"
    top: "g_conv_8"
}

layer {
    name: "g_conv_9"
    type: "Convolution"
    bottom: "g_conv_8"
    top: "g_conv_9"
    param {
        lr_mult: -1
        decay_mult: -1
    }
    param {
        lr_mult: -2
        decay_mult: 0
    }
    convolution_param{
        num_output: 3
        pad: 1
        stride: 1
        kernel_size: 3
    }
}

layer {
	bottom: "g_conv_9"
	top: "g_conv_9"
	name: "g_bn_9"
	type: "BatchNorm"
	batch_norm_param {
		use_global_stats: false
	}
}

layer {
	bottom: "g_conv_9"
	top: "g_conv_9"
	name: "g_scale_9"
	type: "Scale"
	scale_param {
		bias_term: true
	}
}

layer {
    name: "g_sigmoid_9"
    type: "Sigmoid"
    bottom: "g_conv_9"
    top: "g_conv_9"
}
# concat the g_deconv and color_image

layer {
    name: "concat_2"
    type: "Concat"
    bottom: "color_image"
    bottom: "g_conv_9"
    top: "concat_2"
    concat_param{
        axis:0
    }
}

layer {
    name: "d_conv_1"
    type: "Convolution"
    bottom: "concat_2"
    top: "d_conv_1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 2
        decay_mult: 0
    }
    convolution_param{
        num_output: 64
        pad: 1
        stride: 1
        kernel_size: 3
    }
}


layer {
    name: "d_relu_1"
    type: "ReLU"
    bottom: "d_conv_1"
    top: "d_conv_1"
}
layer {
    name: "d_dropout_1"
    type: "Dropout"
    bottom: "d_conv_1"
    top: "d_conv_1"
    dropout_param{
        dropout_ratio: 0.25
    }
}
layer {
    name: "d_pooling_1"
    type: "Pooling"
    bottom: "d_conv_1"
    top: "d_pooling_1"
    pooling_param{
        pool: AVE
        kernel_size: 2
        stride: 2
    }
}

layer {
    name: "d_conv_2"
    type: "Convolution"
    bottom: "d_pooling_1"
    top: "d_conv_2"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 2
        decay_mult: 0
    }
    convolution_param{
        num_output: 128
        pad: 1
        stride: 1
        kernel_size: 3
    }
}


layer {
    name: "d_relu_2"
    type: "ReLU"
    bottom: "d_conv_2"
    top: "d_conv_2"
}
layer {
    name: "d_dropout_2"
    type: "Dropout"
    bottom: "d_conv_2"
    top: "d_conv_2"
    dropout_param{
        dropout_ratio: 0.25
    }
}

layer {
    name: "d_conv_3"
    type: "Convolution"
    bottom: "d_conv_2"
    top: "d_conv_3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 2
        decay_mult: 0
    }
    convolution_param{
        num_output: 256
        pad: 1
        stride: 1
        kernel_size: 3
    }
}


layer {
    name: "d_relu_3"
    type: "ReLU"
    bottom: "d_conv_3"
    top: "d_conv_3"
}
layer {
    name: "d_dropout_3"
    type: "Dropout"
    bottom: "d_conv_3"
    top: "d_conv_3"
    dropout_param{
        dropout_ratio: 0.25
    }
}
layer {
    name: "d_pooling_3"
    type: "Pooling"
    bottom: "d_conv_3"
    top: "d_pooling_3"
    pooling_param{
        pool: MAX
        kernel_size: 2
        stride: 2
    }
}


layer {
    name: "d_fc_4"
    type: "InnerProduct"
    bottom: "d_pooling_3"
    top: "d_fc_4"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 2
        decay_mult: 0
    }
    inner_product_param {
        num_output: 128
    }

}
layer {
    name: "d_prelu_4"
    type: "PReLU"
    bottom: "d_fc_4"
    top: "d_fc_4"
}

layer {
    name: "d_dropout_4"
    type: "Dropout"
    bottom: "d_fc_4"
    top: "d_fc_4"
    dropout_param{
        dropout_ratio: 0.5
    }
}

layer {
    name: "d_fc_5"
    type: "InnerProduct"
    bottom: "d_fc_4"
    top: "d_fc_5"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 2
        decay_mult: 0
    }
    inner_product_param {
        num_output: 1
    }

}
layer {
    name: "sigmoid_loss"
    type: "SigmoidCrossEntropyLoss"
    bottom: "d_fc_5"
    bottom: "label"
    top: "sigmoid_loss"
}
#layer {
    #name: "d_sigmoid_5"
    #type: "Sigmoid"
    #bottom: "d_fc_5"
    #top: "d_sigmoid_5"
#}
#layer {
    #name: "GANLoss"
    #type: "GANLoss"
    #bottom: "d_sigmoid_5"
    #top: "GANLoss"
    #ganloss_param{
        #batch_size: 32  #same as input_data.batchsize
    #}
#}
